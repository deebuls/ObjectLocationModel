
\chapter{Knowledge-enabled Fault Tolerant Search}
\label{cha}


The problem we like to solve is to find people or objects in domestic environments, with the assumption that the detectors are faulty. Domestic service robots need to be able to recognize the objects or persons theyâ€™re supposed to search. While vision based object and person recognition is one of the most widely studied topics in artificial intelligence, even the best detectors still encounter failures. Most of the state-of-art detectors are based on machine learning methodologies. The detectors always publish their \emph{detection probability}. The detection probability quantifies the success rate of the recognizing an object or person. This chapter explores methods of using the learned location probabilities and detection probabilities to accomplish a search task more efficiently in a domestic environment. 


Efficient searching for objects in the environment is one of the application for the knowledge being learned from object locations. The learned knowledge about location probabilities can be used as heuristics to improve the search time of objects. There are 2 basic methods in which we can use the learned knowledge as heuristics, first we can search for objects in the decreasing order of the learned probabilities or alternatively we can use the descriptive model to predict based on its learned probabilities. However the probabilistic representation of the learned knowledge can be used in ingenious way to solve more complex problems. 

In robotics \cite{chung2007decision} formulated the search control problem as a decision-making problem. The formulation of the search problem can include the information of false alarms and false detection. \cite{roy2003planning} demonstrated a system of finding people in a health care setting using a state probabilities of the people in a Partially Observable Markov Decision process planner. 

\missingfigure{Image with false detection}

All these demonstration showed the different ways the learned probabilities can be used to make more informed decisions for the search problem. We here illustrate how the learned probabilities can be used to make a \emph{sequential decision search algorithm} which can accommodate the recognition failure of the vision algorithms. The proposed algorithm here combines both the \emph{detection probability} and the \emph{learned probability} of the objects and provides sequential decisions for the next location to search.

\section{Probabilistic Search}

The robot is assumed to begin with map of the environment, learned knowledge as a probability distributions over where the people and objects might be located and the detection probability for each object and person. The robot can move around in the environment to look for the person or object, perceives the environment. 
The idea is to use the learned knowledge of the object locations as the first guess (prior ) of the probabilities that the object in question is located in each of the possible object locations. The prior probabilities suggest which location to search first. If the object is not found in that location, the prior probabilities are then updated (yielding the posterior), and the process is repeated until the object is found. 

Assume that the domain of interest is a home we call $D_s$, which is made up of n spatial areas. Let $Y_i = 1$ if the object is in the \emph{i}th location, and then $Y_i = 0$ if it is not; $ i = 1, .... , n$. Now as discussed above object detectors can fail to detect the object. So, let $Z_i = 1$ if the object is found in the \emph{i}th location, and $Z_i = 0$ if not.

We can define two terms \emph{detection probability},
\begin{equation}
	p_i = Pr(Z_i = 1| Y_i =1), \qquad  i = 1,...,n,
\end{equation}
which is a conditional probability, and the \emph{occurrence probability},
\begin{equation}
	\pi_i = Pr(Y_i = 1),\qquad  i = 1, .... , n.
\end{equation}

This can be expressed in probabilistic programming form:
\begin{gather}
	Z_i | Y_i \sim Bernoulli (Y_i, p_i), \qquad  i  = 1,....,n \\
	Y_i \sim Bernoulli(\pi_i),\qquad   i = 1,...,n,
\end{gather}

where, the occurrence probability {$\pi_i$} is given by the learned probabilities, while the detection probability {$\pi_i$} is provided by the object detector algorithm.

Now, assume that hte \emph{i}th location is searched by the robot and the object is not found (i.e., $Z_i = 0$). In that case, the probability that the object is in the \emph{i}th location is updated using Bayes' Theorem. This yields the posterior probability,

\begin{gather*}
	Pr(Y_i = 1 | Z_i = 0) = \frac{Pr(Z_i = 0|Y_i=1)Pr(Y_i=1)} {Pr(Z_i=0)} \\
	                       = \frac{Pr(Z_i = 0| Y_i =1 )Pr(Y_i =1)}{Pr(Z_i=0|Y_i =1)Pr(Y_i = 1) + Pr(Z_i=0|Y_i=0)Pr(Y_i=0)} \\
	                       = \frac{(1 - p_i)\pi_i}{(1 - p_i)\pi_i + (1)(1 - \pi_i)} \\
	                       = \frac{(1 - p_i)\pi_i}{1 - p_i\pi_i}
\end{gather*}

where we assume that there are no false-positive detection (i.e., $Pr(Z_i =0| Y_i = 0) = 1$). Note that the new posterior is less than the prior probability $\pi_i$ as the object was not observed.

Since the object is not found in the searched location, then this should also affect the posterior probability in the other grid boxes. For example, consider the \emph{j}th location, where $j \neq i$. Then,
\begin{align*}
	Pr(Y_j = 1 | Z_i=0) &= \frac{Pr(Z_i = 0 | Y_j = 1)Pr(Y_j = 1)}{Pr(Z_i = 0)} \\
	                    &= \frac{\pi_j}{ 1 - p_i\pi_i}
\end{align*}

Thus, the posterior probability of the object being the \emph{j}th location is greater than the prior probability $\pi_j$ . These new posteriors will then become the next prior probabilities is a sequential procedure that would determine the next location to search.


\section{Example}

Suppose we have a domestic robot which has learned the location probabilities of a cup in a home. The robot has learned that the cup can be found 3 locations in the home, thus the domain for search can be defined as $D_s = \{cupboard, table, dishwasher \}$ . 
Now lets assume the robot has been in the room for long enough and made some observations. Based on these observations it learns the occurrence probabilities as $p_i = \{ 0.8, 0.1, 0.1\}$ . The object detector for the cup has a \emph{detection probability} of $p_{cup} =  0.6$ .

As you can see there is a strong probability of finding the cup in the cupboard. The algorithm selects to search the cupboard. But the object detector fails and is not able to detect the cup. If we are not using the algorithm the robot will move on to the next location to search the cup in the next location.


\missingfigure{Illustration of the proabbiliities and how they change with each observation}

However our algorithm on the failure detection will update its probabilities and the updated posterior probability will be $ p_i = \{ 0.44, 0.27, 0.27\}$ and it still selects to search the cupboard for the next time. This illustrates the algorithm understands the limitation in the object detector and updates its beliefs to accommodate this limitation and make better \emph{informed} decisions.  

\todo[inline]{split as 2 example , 1 with high detection probability 0.9 and other with 0.6}

\section{Discussion}

\todo[inline]{TODO}
% chapter  (end)