\chapter{Learning User Preferences In Object Placement}
\label{chapter: object}

As robots achieve long term autonomy and they intend to stay longer in human environments, they should be ability to adapt quickly to the corresponding environments especially to the humans within. As a robot makes new observations, it should attempt to use these observations to learn about the user preferences. In this chapter we discuss on problem to enable a robot to learn about user preferences in object placement in a specific home. 

In a series of interviews to understand the needs of people with robots, \cite{pantofaru_exploring_2012} concludes that one of the
expectations from robots is help in organizing things based on the user preferences. Since they are service robots it is acceptable for a new robot to ask for help from its user in the initial days it moves to a new home. But as the robot stays longer in a home it becomes less acceptable that the robot asks the same questions, i.e. they should have the capabilities to learn from previous information provided by the user. The Robots should also be able to reason and learn from its own observations of the user and the environment. It should have mechanisms to generate new knowledge about the user and environment from all information gathered. For example, the robot can learn about the user preferences of the cutlery used to setup a breakfast table from observations of breakfast tables in the past. In this chapter we look at such one example of knowledge generation based on previous observations, for learning the user preferences in object placement.

The advantage of learning user preference about object placement would be in object search. In classical object search, the search is improved based on the knowledge of object locations in a generic home  (for example, cups are found in kitchen, books in shelves) by \cite{samadi_using_2012, joho_learning_2011}. The above method is good for a new robot but after long time stay, the robot needs to adapt its beliefs for searching based on its user's preferences. Another use of the user preferences will be in organizing the home. Here the robot should learn  about the default locations of different objects, so that the robot can return any misplaced objects back to their locations. Understanding user preferences in organizing objects in a home has 
been studied by  \cite{abdo2015robot}, where robots learn based on the data collected via crowd-sourcing.  From practical experience we know that even though homes have same base structure in space, the usage of space is based on the user preferences. Each home is different from any other home because the humans which reside in them use it according to their likes  (for example, some users the keep books on the study table and not on shelves). The proposed methods in this chapter will try to enable the robot learn these user preferences specific to each home. So rather than the robot learning object locations in a generic home the proposed methods shall learn object locations in a specific home.


\begin{figure}[htp]
\centering
\includegraphics[scale=0.4]{pictures/scenario.png}
\caption[Example scenario of robot recording objects location and time]{Robot recording objects location and time. Based on the
recordings robot making prediction on the location of the cup for current time
Images courtesy : \citep{willowgarage} }
\label{scenario}
\end{figure}

Autonomous robots in dynamic human environments convert raw data  (e.g. image) to information  (e.g. cup on table) for completing their tasks. This information can be used by the robot to generate knowledge about user preferences. We explain this in the context of the ``make coffee" example introduced in the Chapter~\ref{chapter:Introduction}. 
Consider a domestic robot, which has been placed in a home environment with a known map and semantic information of the different locations in the home. The domestic robot while doing its daily activities over the course of weeks or months, makes records. Now the robot has been asked to bring the coffee mug of the user.
The robot has to decide which part of the home it has to go to look for
the coffee mug. The robot can make this decision based on the previous observations of locations of the coffee mug.
The robot, using these previous observations and the time of those observations,
makes a prediction about where the coffee mug can be found at the current time.
Based on previous observation it can be inferred that the coffee mug is usually found in any of the following three locations: dishwasher,counter or cupboard. Assuming that the time now is morning, from previous observations it can be found that the coffee mug was always found  in the dishwasher. The above example illustrates the main aspects of object location prediction we wish to capture in this chapter.

\section{Approach}

We formulate the problem of learning user preference in object placement, by modelling the belief of \emph{finding an object at a location}. The robot tries to learn the chances of the user of keeping an object  (e.g. cup ) at a location  (e.g. cupboard). Whenever the robot scans a particular location as illustrated in Figure~\ref{fig:counter_scan}, it records present and absent of objects at that location along-with the time of the scan ~\ref{tab:robot_record}.
  
  
  \begin{minipage}{\textwidth}
  \begin{minipage}[b]{0.49\textwidth}
    \centering
        \includegraphics[width=0.9\textwidth]{images/counter_ano.png}

    \captionof{figure}{Robot scanning kitchen counter}
    \label{fig:counter_scan}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.49\textwidth}
    \centering
    \begin{tabular}{|l|l|l|l|}
        \hline
	        Time & Location & Object & Present\\
        \hline
        \hline
	        09.03 & counter & kettle & True\\
        \hline
	        09.03 & counter & tea-bag & True\\
        \hline
	        09.03 & counter & sugar & True\\
        \hline
	        09.03 & counter & cup & True\\
        \hline
	        09.03 & counter & plate & False\\
        \hline
	        09.03 & counter & milk & False\\
        \hline
        \end{tabular}
      \captionof{table}{Robot record}
      \label{tab:robot_record}
    \end{minipage}
  \end{minipage}



This recorded information about each object at each location is modelled using Bayesian models to learn about the belief of a person placing an object at any location.

The observations made by the robot are boolean values (present or absent). As discussed in chapter~\ref{chapter:basics}, when the data type is boolean we can use the Bernoulli Distribution with a Beta distribution prior to model the observations. To capture the belief at different times of the day, we create 24 Bernoulli variables, one for each hour. For coping with the problem of sparsity of observations in all time periods, we also add a hyper-prior. The addition of the hyper-prior causes of sharing of learning knowledge in one time period with other time periods. The model is called as the \textbf{Hierarchical Beta Bernoulli}(HBB)  model. In the next section we explain the generative model along with the graphical diagram. 


\section{Hierarchical Beta Bernoulli Model}

Hierarchical Beta Bernoulli model is a three-level Bayesian model. The basic idea is that observations of the presence of an object at a location (first level), is characterized by a distribution for each hour (second level), which share information via a common latent distribution (third level).

The data are the boolean observation of the object at a location $x_{ij}$ for $i = 1 \dots T$ time periods and then $j = 1, \dots , N$  are the observations.  We assume that the latent pattern that the user will place the object at a  location in a particular period can be represented as a Bernoulli distribution. The number of periods $T$ for our model is fixed to 24 corresponding to the number of hours in a day. 

The conjugate prior for the Bernoulli distribution is the Beta distribution. The model estimates the posterior distribution of $\theta_i$ given our current data and prior beliefs. Our prior beliefs are encoded in the model through the prior $\alpha$ and $\beta$, which represents pseudocounts of what we believe the data should look like â€“ currently taken as same values representing no prior information. The probabilistic graphical model is shown in Figure \ref{bbm}

\noindent
\begin{figure}[htp]

\begin{minipage}{0.3\textwidth}
\centering

\tikz {
 % Define nodes
  \node[latent]                                  (theta) {$\theta$};
  \node[latent, above=of theta, xshift=-1.2cm]   (alpha) {$\alpha$};
  \node[latent, above=of theta, xshift=1.2cm]    (beta) {$\beta$};
  \node[obs, below=of theta]                     (y)     {$x$}; 
  % Connect the nodes
  \edge {alpha,beta} {theta} ; %
  \edge {theta} {y};
  % plates
  \plate {location} { (y)} {location};
  \plate {time} { (theta) (y) (location)} {time};
}

\end{minipage}%
\begin{minipage}{0.7\textwidth}

\begin{equation*}
	\alpha \sim Beta (2,2) ; \beta \sim Beta (2, 2);
\end{equation*}
\begin{equation*}
	\theta \sim Beta (\alpha, \beta);
\end{equation*}
\begin{equation*}
	x = Bernoulli (\theta)
\end{equation*}
\end{minipage}
\caption[Hierarchical Beta Bernoulli graphical model]{Graphical model representation of Hierarchical Beta Bernoulli model. The boxes are ``plates" representing replicates. The outer plates represents hours of a day, while the inner plate represents whether object was observed at the location each hour.}
\label{bbm}
\end{figure}

The models are implemented using the PyMC3 probabilistic programming language.

\FloatBarrier
\section{Experiments}

We tested our approach on artificially generated datasets as well as on a real dataset of object locations collected by a long term robot.
The goal of the experiments were to
\begin{itemize}
    \item verify that the robot is able to learn the user preference in placing an object at a particular location
	\item empirically conclude on the minimum number of times a location needs to be scanned before a robot can start predicting with 80\% confidence?
	\item evaluate the accuracy of the developed model.
\end{itemize}

\subsection{Evaluation Of Number Of Observations Required}

To quantitatively evaluate the accuracy of the learned model we generated a synthetic dataset of object locations, with known ground truth. The dataset consists of observations, made by a mobile domestic robot, of a cup on the counter during different times of the day. The robot scans the counter-top of the kitchen while doing its daily chores. While doing so it records all the instances that it finds the cup on the counter. Figure \ref{simulation} shows the ground truth probabilities as well as the count of the different observations generated from the ground truth.

\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{images/object_simulation.png}
\caption[Simulated object location dataset]{Simulated Object location dataset: Ground truth probabilities of finding a cup on the counter during different times of the day. Observation count of the dataset generated from the ground truth probabilities}
\label{simulation}
\end{figure}

The generated dataset is provided to the HBB model which runs its inference algorithms and updates its posterior probabilities. The performance of the model can be measured by using the distance between the learned probability and the ground truth probability.  The distance between the learned and ground probabilities is measured using the Bhattacharyya distance. The learned models were also validated using cross-validation technique. Each dataset was split into training and testing dataset. The training set was used for learning while the testing set was used for validation. Based on the validation we measure the accuracy score. 


\subsubsection*{Bhattacharyya distance}
We use the Bhattacharyya distance \cite{bhattacharyya1946measure} to quantify the distance between the learned probability and the ground truth. Bhattacharyya distance measures the similarity of two discrete or continuous probability distributions. 
Let  $p$ and $q$ be two discrete probability distributions over the same domain $X$. The Bhattacharyya co-efficient \cite{bhattacharyya1946measure} is a divergence-type measure between distributions, defined as,
\begin{equation}
	BC = \sum_{x\in X}\sqrt{p (x)  q (x)} 
\end{equation}

If $p (\theta_i)$ and $p (\theta_j)$ represent two Bernoulli distributions, then the Bhattacharyya co-efficient is derived as,
\begin{equation}
	BC (p (\theta_i), p (\theta_j)) = \sqrt{p (\theta_i) p (\theta_j)} + \sqrt{p (1- \theta_i) p (1 - \theta_j)}
\end{equation}

When both the probabilities are same $BC = 1$ . The Bhattacharyya distance is then provided by 
\begin{equation}
    D_B = -\log (BC)
\end{equation}

The Bhattacharyya distance ranges from 0 to $\infty$, with \textbf{0} meaning both probabilities are identical. 


\subsubsection*{Accuracy }

The accuracy is the proportion of correct predictions \cite{scikit-learn} . If $p_i$ is the predicted value of the $i_th$ sample and $o_i$ is the corresponding true value, then the fraction of correct predictions over $n_{samples}$ is defined as 

\begin{equation}
	accuracy (p, o) = \frac{1}{n_samples} \sum_{i=0}^{n_{samples} -1 }1 (p_i = o_i)
\end{equation} 

where $ 1 (x)$ is the indicator function.


We evaluated the number of observations required to learn a pattern by comparing the learned models  probabilities with the ground truth per time period. The model is trained with increasing number of observations, and the learned probabilities are compared with the ground truth. For each size of the observations, the procedure is repeated 100 times using different ground truth probabilities.

\subsubsection*{Results}
The Bhattacharyya distance between the posterior probability and the ground truth probability is shown in Figure \ref{fig:object_simulation_distance}. The accuracy of the model using increasing number of training is show in Figure \ref{fig:object_simulation_accuracy}. We can observe from the results that with \textbf{25} observations the mean distance is reduced below 0.01 and the accuracy is above 80\%. Thus we can empirically conclude that a minimum of \textbf{25} observations per location had to be made by the robot to make valid predictions of the object locations. 

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{images/object_simulation_error.png}
        \caption{}
        \label{fig:object_simulation_distance}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      % (or a blank line to force the subfigure onto a new line)
      \qquad
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{images/object_simulation_accuracy.png}
        \caption{}
        \label{fig:object_simulation_accuracy}
    \end{subfigure}
    \caption[Evaluation of number of observation required]{Evaluation of number of observation required: Distance between ground truth and learned probabilities (a). The accuracy of the learned models using different number of observations (b) }\label{fig:object_simulation_accuracy}
\end{figure}

\FloatBarrier
\subsection{Evaluation Of Model Accuracy}

In this section we evaluate the accuracy of the model by using a real world dataset. The KTH Object dataset \cite{krajnik_wheres_2015}, was collected in the Computer Vision and Active Perception lab at KTH Stockholm, by a SCITOS-G5 mobile robot over  the  course  of  five  weeks.  The robot conducts two to six autonomous patrols per day, around the lab, visiting three waypoints. On reaching each waypoint the robot would scan the area using a pan-tilt sweep. In each sweep the data from its RGB-D sensor are collected. The KTH dataset contains approximately 100 observations per waypoint. The dynamic objects of the environment were identified  using the `MetaRoom' method by \cite{ambrucs2014meta}. There were 37 different dynamic objects identified by the algorithms. These objects were manually labelled by \cite{krajnik_wheres_2015}.

\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{images/kth-dataset-fromsite.png}
\caption[KTH dataset collection]{KTH dataset collection \cite{krajnik_wheres_2015}. Object retrieval from point cloud data. The points depicted as green denote dynamic objects in the environment}
\label{fig:KTH-dataset}
\end{figure}



\subsubsection*{Results}

The first four weeks of the KTH dataset is used to train the models and the fifth week is used to evaluate the learned model. The accuracy results of 37 objects is plotted in Figure~\ref{fig:kth_object_evaluation} . 
Out of the 37 objects \textbf{26} objects have a accuracy rate of above \textbf{70\%} which is denoted by the dotted line. Most of these 26 objects were static objects like chairs, computers etc. as a result of which they had good accuracy. The model was not able to accurately predict locations of objects that had seemingly random patterns of locations.
\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{images/evaluation_kth.png}
\caption[Cross validation results]{Cross validation results. x-axis is the name of the object, y-axis represents the accuracy in predicting the locations of the objects. }
\label{fig:kth_object_evaluation}
\end{figure}

\FloatBarrier
\section{Discussion}
In this chapter, we presented a probabilistic model for learning user preference in placing an object at a particular location. 
Our first contribution is to represent the user preferences of object placement using graphical model. 
Our second contribution is that the graphical model has been implemented using a probabilistic programming language. 
The robot continuously learns about where the user prefers to keep his objects in the home from the set of object location observations. 
Since the observations are not a continuous trace but just random instances of the objects, the model was designed to be able to capture the latent knowledge in the placement preferences from such sporadic observations.

We have shown by evaluation that the robot needs minimum 25 observations per location to make valid prediction about the object being in that location in this dataset. As seen from evaluation objects which are not moved very often are learned very easily by our models using few observations. The model performs badly when there is no preference in the user placement i.e. it seems the user places randomly. 
From the real world experiments we can conclude that a majority of the objects in our home environments are rarely moved by the user, therefore our model is able to learn and predict accurately for most of the objects. 

The approaches here capture knowledge about each object in each location separately, we will see in chapter \ref{chapter:Human location} how knowledge about multiple locations of the object can be captured in a single model.