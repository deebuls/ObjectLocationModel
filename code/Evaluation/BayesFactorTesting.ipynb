{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Factor\n",
    "\n",
    "A quick tutorial on how to obtain Bayes factors from BayesPy. Lets use a simple example taken from Chapter 7 of Link and Barker (2010). \n",
    "Consider a short vector of data, consisting of 5 integers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = np.array([0,1,2,3,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to determine which of two functional forms best models this dataset. The first is a geometric model:\n",
    "\n",
    "$$f(x|p)=(1−p)xp$$\n",
    "\n",
    "and the second a Poisson model:\n",
    "\n",
    "$$f(x|μ)=μxe−μx!$$\n",
    "\n",
    "Both describe the distribution of non-negative integer data, but differ in that the variance of Poisson data is equal to the mean, while the geometric model describes variance greater the mean. For this dataset, the sample variance would suggest that the geometric model is favored, but the sample is too small to say so definitively.\n",
    "\n",
    "In order to calculate Bayes factors, we require both the prior and posterior odds:\n",
    "\n",
    "    Bayes factor = Posterior odds / Prior odds\n",
    "\n",
    "The Bayes factor does not depend on the value of the prior model weights, but the estimate will be most precise when the posterior odds are the same. For our purposes, we will give 0.1 probability to the geometric model, and 0.9 to the Poisson model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = (0.1, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to specify a latent variable, which identifies the true model (we don't believe either model is \"true\", but we hope one is better than the other). This is easily done using a Bernoulli random variable, that identifies one model or the other, according to their relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayespy.nodes import Bernoulli\n",
    "true_model = Bernoulli('true_model', p=pi[1], value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
